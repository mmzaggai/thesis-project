{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5470359d-c201-4ba6-a0bb-46f3d208c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MIN_TOPIC_SIZE = 50 ---\n",
      "Topics: 102, Total docs: 21,713\n",
      "   Topic  Count                          Name\n",
      "1      0   1518            0_land_the_jews_of\n",
      "2      1   1018      1_hamas_hamas is_is_they\n",
      "3      2    864      2_idf_the idf_the_idf is\n",
      "4      3    819             3_land_you_the_to\n",
      "5      4    788  4_israel_us_the us_israel is\n",
      "\n",
      "--- MIN_TOPIC_SIZE = 30 ---\n",
      "Topics: 163, Total docs: 21,749\n",
      "   Topic  Count                                      Name\n",
      "1      0    875                  0_idf_the idf_idf is_the\n",
      "2      1    805                      1_you_my_answer_your\n",
      "3      2    766    2_hamas_hamas is_support_support hamas\n",
      "4      3    627  3_genocide_group_of genocide_genocide is\n",
      "5      4    588              4_israel_us_the us_israel is\n",
      "\n",
      "--- MIN_TOPIC_SIZE = 10 ---\n",
      "Topics: 436, Total docs: 22,909\n",
      "   Topic  Count                                       Name\n",
      "1      0    870              0_idf_the idf_idf is_soldiers\n",
      "2      1    592  1_genocide_intent_of genocide_genocide is\n",
      "3      2    587   2_genocide_of genocide_genocide is_group\n",
      "4      3    384               3_islam_muslim_muslims_quran\n",
      "5      4    378                 4_she_her_she was_that she\n",
      "MIN_TOPIC_SIZE=50 → topic diversity=0.61\n",
      "MIN_TOPIC_SIZE=30 → topic diversity=0.72\n",
      "MIN_TOPIC_SIZE=10 → topic diversity=0.84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_topic_size</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>mean_docs_per_topic</th>\n",
       "      <th>median_docs_per_topic</th>\n",
       "      <th>max_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>102</td>\n",
       "      <td>212.872549</td>\n",
       "      <td>132.5</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>163</td>\n",
       "      <td>133.429448</td>\n",
       "      <td>85.0</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>436</td>\n",
       "      <td>52.543578</td>\n",
       "      <td>29.0</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_topic_size  num_topics  mean_docs_per_topic  median_docs_per_topic  \\\n",
       "0              50         102           212.872549                  132.5   \n",
       "1              30         163           133.429448                   85.0   \n",
       "2              10         436            52.543578                   29.0   \n",
       "\n",
       "   max_topic  \n",
       "0       1518  \n",
       "1        875  \n",
       "2        870  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 6 - compare the results from BERTopic\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "summaries = {}\n",
    "for size in [50, 30, 10]:\n",
    "    df = pd.read_csv(f\"topic_summary_mts{size}.csv\")\n",
    "    summaries[size] = df[df[\"Topic\"] != -1]  # skip outliers/unassigned\n",
    "    print(f\"\\n--- MIN_TOPIC_SIZE = {size} ---\")\n",
    "    print(f\"Topics: {len(summaries[size])}, Total docs: {summaries[size]['Count'].sum():,}\")\n",
    "    print(summaries[size].head(5)[[\"Topic\",\"Count\",\"Name\"]])\n",
    "\n",
    "def topic_diversity(model_topics):\n",
    "    top_words = [set(t.split(\", \")) for t in model_topics]\n",
    "    all_words = sum((list(t) for t in top_words), [])\n",
    "    unique_words = len(set(all_words))\n",
    "    total_words = len(all_words)\n",
    "    return unique_words / total_words\n",
    "\n",
    "for size in [50, 30, 10]:\n",
    "    top_words = summaries[size][\"Representation\"].astype(str).tolist()\n",
    "    div = topic_diversity(top_words)\n",
    "    print(f\"MIN_TOPIC_SIZE={size} → topic diversity={div:.2f}\")\n",
    "\n",
    "summary = []\n",
    "for size, df in summaries.items():\n",
    "    summary.append({\n",
    "        \"min_topic_size\": size,\n",
    "        \"num_topics\": len(df),\n",
    "        \"mean_docs_per_topic\": df[\"Count\"].mean(),\n",
    "        \"median_docs_per_topic\": df[\"Count\"].median(),\n",
    "        \"max_topic\": df[\"Count\"].max()\n",
    "    })\n",
    "\n",
    "pd.DataFrame(summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.8 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-25.2\n",
      "Requirement already satisfied: wordcloud in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (2.1.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (11.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\matilde\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\matilde\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\matilde\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade pip\n",
    "%pip install wordcloud matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaca07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Saved 12 individual wordclouds and grid → wordclouds\\wordclouds_grid_mts50.png\n",
      "[ok] Saved 12 individual wordclouds and grid → wordclouds\\wordclouds_grid_mts30.png\n",
      "[ok] Saved 12 individual wordclouds and grid → wordclouds\\wordclouds_grid_mts10.png\n"
     ]
    }
   ],
   "source": [
    "# Wordclouds for BERTopic summaries (mts=50,30,10)\n",
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Config\n",
    "FILES = {\n",
    "    50: \"topic_summary_mts50.csv\",\n",
    "    30: \"topic_summary_mts30.csv\",\n",
    "    10: \"topic_summary_mts10.csv\",\n",
    "}\n",
    "TOP_K_TOPICS = 12          # how many topics per run to visualize\n",
    "GRID_COLS = 4              # grid columns for montage\n",
    "WC_MAX_WORDS = 80          # max words per wordcloud\n",
    "WC_WIDTH = 900\n",
    "WC_HEIGHT = 600\n",
    "OUTPUT_DIR = Path(\"wordclouds\")\n",
    "\n",
    "# Helpers \n",
    "def parse_representation(rep):\n",
    "    \"\"\"\n",
    "    Robustly parse the 'Representation' column to a list of words.\n",
    "    It can be:\n",
    "      - a python-list-like string: \"['word1', 'word2', ...]\"\n",
    "      - a comma/space separated string: \"word1, word2, word3\"\n",
    "    \"\"\"\n",
    "    if not isinstance(rep, str):\n",
    "        return []\n",
    "    rep = rep.strip()\n",
    "    words = []\n",
    "    # Try list literal first\n",
    "    if rep.startswith(\"[\") and rep.endswith(\"]\"):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(rep)\n",
    "            if isinstance(parsed, (list, tuple)):\n",
    "                words = [str(w) for w in parsed]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not words:\n",
    "        # Fallback: split on commas\n",
    "        parts = [w.strip() for w in rep.split(\",\")]\n",
    "        # If it didn't contain commas, split on whitespace\n",
    "        if len(parts) == 1:\n",
    "            parts = rep.split()\n",
    "        words = [re.sub(r\"[^a-zA-Z0-9_\\-]+\", \"\", w) for w in parts if w]\n",
    "\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for w in words:\n",
    "        wl = w.lower()\n",
    "        if wl and wl not in seen:\n",
    "            seen.add(wl)\n",
    "            out.append(wl)\n",
    "    return out\n",
    "\n",
    "def rank_weights(words, base_weight=1.0, decay=0.9):\n",
    "    \"\"\"\n",
    "    Assign descending weights by rank: w0=base, w1=base*decay, ...\n",
    "    Returns dict word->weight suitable for WordCloud.generate_from_frequencies().\n",
    "    \"\"\"\n",
    "    freqs = {}\n",
    "    for i, w in enumerate(words):\n",
    "        freqs[w] = base_weight * (decay ** i)\n",
    "    return freqs\n",
    "\n",
    "def make_wordcloud(freqs, title=None, width=WC_WIDTH, height=WC_HEIGHT, max_words=WC_MAX_WORDS):\n",
    "    wc = WordCloud(width=width, height=height, background_color=\"white\", max_words=max_words)\n",
    "    wc_img = wc.generate_from_frequencies(freqs)\n",
    "    fig, ax = plt.subplots(figsize=(width/100, height/100), dpi=100)\n",
    "    ax.imshow(wc_img, interpolation=\"bilinear\")\n",
    "    ax.axis(\"off\")\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=14, pad=6)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def grid_wordclouds(entries, cols=GRID_COLS, title=None, save_path=None):\n",
    "    \"\"\"\n",
    "    entries: list of (fig_title, freq_dict)\n",
    "    Renders a grid of wordclouds.\n",
    "    \"\"\"\n",
    "    n = len(entries)\n",
    "    rows = math.ceil(n / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*3.8, rows*3.0), dpi=150)\n",
    "    if rows == 1 and cols == 1:\n",
    "        axes = [[axes]]\n",
    "    elif rows == 1:\n",
    "        axes = [axes]\n",
    "    elif cols == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax = axes[r][c]\n",
    "            ax.axis(\"off\")\n",
    "            if idx < n:\n",
    "                t, freqs = entries[idx]\n",
    "                wc = WordCloud(width=600, height=400, background_color=\"white\", max_words=WC_MAX_WORDS)\n",
    "                img = wc.generate_from_frequencies(freqs)\n",
    "                ax.imshow(img, interpolation=\"bilinear\")\n",
    "                ax.set_title(t, fontsize=10, pad=4)\n",
    "                idx += 1\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0.02, 1, 0.98])\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "    return fig\n",
    "\n",
    "# Main\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for mts, path in FILES.items():\n",
    "    if not Path(path).exists():\n",
    "        print(f\"[skip] {path} not found.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    if \"Topic\" not in df.columns or \"Count\" not in df.columns or \"Representation\" not in df.columns:\n",
    "        print(f\"[warn] {path} missing expected columns (Topic, Count, Representation). Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Drop the outlier topic (-1) and take top-K by Count\n",
    "    topics_df = df[df[\"Topic\"] != -1].copy()\n",
    "    topics_df = topics_df.sort_values(\"Count\", ascending=False).head(TOP_K_TOPICS)\n",
    "\n",
    "    # Build entries: (title, freq_dict)\n",
    "    entries = []\n",
    "    for _, row in topics_df.iterrows():\n",
    "        topic_id = int(row[\"Topic\"])\n",
    "        rep = row[\"Representation\"]\n",
    "        words = parse_representation(rep)\n",
    "        freqs = rank_weights(words, base_weight=1.0, decay=0.92)\n",
    "        label = row[\"Name\"] if \"Name\" in row and isinstance(row[\"Name\"], str) and row[\"Name\"].strip() else f\"Topic {topic_id}\"\n",
    "        title = f\"{label} (#{topic_id})\"\n",
    "        entries.append((title, freqs))\n",
    "\n",
    "        # Save individual wordcloud\n",
    "        fig = make_wordcloud(freqs, title=title)\n",
    "        indiv_path = OUTPUT_DIR / f\"wordcloud_mts{mts}_topic{topic_id}.png\"\n",
    "        fig.savefig(indiv_path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Save grid montage\n",
    "    grid_path = OUTPUT_DIR / f\"wordclouds_grid_mts{mts}.png\"\n",
    "    grid_wordclouds(entries, cols=GRID_COLS, title=f\"Top {len(entries)} topics — min_topic_size={mts}\", save_path=grid_path)\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    print(f\"[ok] Saved {len(entries)} individual wordclouds and grid → {grid_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
