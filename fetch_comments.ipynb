{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb9207-b6c5-4811-92c6-38651643b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 — FETCH COMMENTS\n",
    "# Inputs: ip_posts.csv\n",
    "# Outputs: ip_comments.csv\n",
    "\n",
    "# %pip install praw pandas tqdm\n",
    "# Inspired by [https://praw.readthedocs.io/en/stable/tutorials/comments.html](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "# [https://www.kaggle.com/code/gpreda/collect-and-update-data-on-reddit](https://www.kaggle.com/code/gpreda/collect-and-update-data-on-reddit)\n",
    "# [https://github.com/loganblackstad/Universal-Reddit-Scraper/tree/master](https://github.com/loganblackstad/Universal-Reddit-Scraper/tree/master)\n",
    "# download_threads.ipynb)\n",
    "\n",
    "import os\n",
    "\n",
    "# Reddit API keys (same as Step 1)\n",
    "CLIENT_ID     = \"...\"        \n",
    "CLIENT_SECRET = \"...\" \n",
    "USER_AGENT    = \"...\"\n",
    "\n",
    "# Input from Step 1\n",
    "POSTS_CSV = \"ip_posts.csv\"   # produced by Step 1\n",
    "\n",
    "# Outputs for Step 2 (comments)\n",
    "COMMENTS_CSV   = \"ip_comments.csv\"\n",
    "COMMENTS_JSONL = \"ip_comments.jsonl\" \n",
    "\n",
    "# Politeness / limits \n",
    "SLEEP_BETWEEN_REQUESTS = 0.4\n",
    "MAX_SUBMISSIONS_THIS_RUN = None   # 200 to test or None for all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb42c4-0a20-43b7-865d-5082a50cbc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matilde\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time, csv, json\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional, List, Iterable, Dict\n",
    "from tqdm.auto import tqdm\n",
    "import praw\n",
    "\n",
    "@dataclass\n",
    "class CommentRow:\n",
    "    id: str\n",
    "    created_utc: int\n",
    "    subreddit: str\n",
    "    link_id: str        \n",
    "    parent_id: str\n",
    "    author: Optional[str]\n",
    "    body: Optional[str]\n",
    "    score: Optional[int]\n",
    "    submission_id: str\n",
    "    submission_flair: Optional[str]\n",
    "\n",
    "COM_FIELDS = [f.name for f in CommentRow.__dataclass_fields__.values()]\n",
    "\n",
    "def ensure_csv(path: str, fields: List[str]):\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            csv.DictWriter(f, fieldnames=fields).writeheader()\n",
    "\n",
    "def append_csv(path: str, rows: Iterable[dict], fields: List[str]):\n",
    "    if not rows:\n",
    "        return\n",
    "    with open(path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=fields)\n",
    "        for r in rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "def append_jsonl(path: str, rows: Iterable[dict]):\n",
    "    if not rows or not path:\n",
    "        return\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def load_seen_ids(path: str, id_field: str) -> set:\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        return set()\n",
    "    try:\n",
    "        return set(pd.read_csv(path, usecols=[id_field])[id_field].astype(str))\n",
    "    except Exception:\n",
    "        seen = set()\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for row in csv.DictReader(f):\n",
    "                seen.add(str(row.get(id_field)))\n",
    "        return seen\n",
    "\n",
    "def init_reddit():\n",
    "    assert all([CLIENT_ID, CLIENT_SECRET, USER_AGENT]) and CLIENT_ID != \"YOUR_CLIENT_ID\", \\\n",
    "        \"Fill CLIENT_ID/CLIENT_SECRET/USER_AGENT in the Config cell.\"\n",
    "    return praw.Reddit(client_id=CLIENT_ID, client_secret=CLIENT_SECRET, user_agent=USER_AGENT, check_for_async=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49d3623-9c0d-498d-9042-9f255e7a81d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3056, ['gf34wp', 'gnle2w', 'ho0fmu', 'hm3cjv', 'i3c9om'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load posts from Step 1\n",
    "posts = pd.read_csv(POSTS_CSV)\n",
    "\n",
    "# Keep only what we need\n",
    "if \"id\" not in posts.columns:\n",
    "    raise ValueError(\"ip_posts.csv must have a column named 'id' (the submission id).\")\n",
    "\n",
    "# Create a flair map (submission_id -> link_flair_text)\n",
    "flair_map = {}\n",
    "if \"link_flair_text\" in posts.columns:\n",
    "    flair_map = dict(zip(posts[\"id\"].astype(str), posts[\"link_flair_text\"].astype(str)))\n",
    "else:\n",
    "    # safe default if Step 1 didn't include flair\n",
    "    flair_map = {sid: None for sid in posts[\"id\"].astype(str)}\n",
    "\n",
    "# De-duplicate submissions and (optionally) cap how many to fetch in this run\n",
    "submission_ids = posts[\"id\"].astype(str).drop_duplicates().tolist()\n",
    "if MAX_SUBMISSIONS_THIS_RUN is not None:\n",
    "    submission_ids = submission_ids[:int(MAX_SUBMISSIONS_THIS_RUN)]\n",
    "\n",
    "len(submission_ids), submission_ids[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e5c0f1-9f09-4b40-9da6-31bdc8d2d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submissions: 100%|██████████| 3056/3056 [2:09:37<00:00,  2.55s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] wrote 140588 comments to ip_comments.csv and ip_comments.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reddit = init_reddit()\n",
    "\n",
    "ensure_csv(COMMENTS_CSV, COM_FIELDS)\n",
    "seen_comment_ids = load_seen_ids(COMMENTS_CSV, \"id\")\n",
    "\n",
    "total_written = 0\n",
    "batch = []\n",
    "\n",
    "for sid in tqdm(submission_ids, desc=\"Submissions\"):\n",
    "    try:\n",
    "        subm = reddit.submission(id=sid)\n",
    "        # Do NOT expand more comments (fast path)\n",
    "        subm.comments.replace_more(limit=0)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] failed to prep submission {sid}: {e}\")\n",
    "        continue\n",
    "\n",
    "    inherited_flair = flair_map.get(sid)\n",
    "\n",
    "    # Flatten whatever is already loaded (top-level + any preloaded replies)\n",
    "    try:\n",
    "        flat = list(subm.comments.list())\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] listing comments failed for {sid}: {e}\")\n",
    "        flat = []\n",
    "\n",
    "    for c in flat:\n",
    "        try:\n",
    "            cid = str(getattr(c, \"id\", \"\"))\n",
    "            if not cid or cid in seen_comment_ids:\n",
    "                continue\n",
    "\n",
    "            row = CommentRow(\n",
    "                id=cid,\n",
    "                created_utc=int(getattr(c, \"created_utc\", 0) or 0),\n",
    "                subreddit=str(getattr(c, \"subreddit\", \"\")),\n",
    "                link_id=str(getattr(c, \"link_id\", \"\")),   # e.g., t3_<sid>\n",
    "                parent_id=str(getattr(c, \"parent_id\", \"\")),\n",
    "                author=str(getattr(c, \"author\", \"\") or \"\") or None,\n",
    "                body=getattr(c, \"body\", None),\n",
    "                score=int(getattr(c, \"score\", 0) or 0),\n",
    "                submission_id=sid,\n",
    "                submission_flair=inherited_flair,\n",
    "            )\n",
    "            batch.append(asdict(row))\n",
    "            seen_comment_ids.add(cid)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Write periodically\n",
    "    if len(batch) >= 2000:\n",
    "        append_csv(COMMENTS_CSV, batch, COM_FIELDS)\n",
    "        if COMMENTS_JSONL:\n",
    "            append_jsonl(COMMENTS_JSONL, batch)\n",
    "        total_written += len(batch)\n",
    "        batch.clear()\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "# Flush any remaining rows\n",
    "if batch:\n",
    "    append_csv(COMMENTS_CSV, batch, COM_FIELDS)\n",
    "    if COMMENTS_JSONL:\n",
    "        append_jsonl(COMMENTS_JSONL, batch)\n",
    "    total_written += len(batch)\n",
    "    batch.clear()\n",
    "\n",
    "print(f\"[done] wrote {total_written} comments to {COMMENTS_CSV}\" + (f\" and {COMMENTS_JSONL}\" if COMMENTS_JSONL else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dda9f3d-40c4-4aa4-8e71-69313083ba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fprlg3x</td>\n",
       "      <td>1588856974</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>RosintheBow3</td>\n",
       "      <td>I think Israelis are critical of their governm...</td>\n",
       "      <td>32</td>\n",
       "      <td>gf34wp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fprapg5</td>\n",
       "      <td>1588848450</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>samtony234</td>\n",
       "      <td>There are many critical Israelis. You have the...</td>\n",
       "      <td>17</td>\n",
       "      <td>gf34wp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fprla8t</td>\n",
       "      <td>1588856871</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>JeffB1517</td>\n",
       "      <td>&gt;  Like all other things, criticisms of Israel...</td>\n",
       "      <td>12</td>\n",
       "      <td>gf34wp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fprymsf</td>\n",
       "      <td>1588864482</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>zidbutt21</td>\n",
       "      <td>Would you mind translating the Hebrew article ...</td>\n",
       "      <td>3</td>\n",
       "      <td>gf34wp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fpta3xd</td>\n",
       "      <td>1588887532</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>t3_gf34wp</td>\n",
       "      <td>ShabbatShalomSamurai</td>\n",
       "      <td>I’ve been in Israel the last five months and I...</td>\n",
       "      <td>3</td>\n",
       "      <td>gf34wp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  created_utc        subreddit    link_id  parent_id  \\\n",
       "0  fprlg3x   1588856974  IsraelPalestine  t3_gf34wp  t3_gf34wp   \n",
       "1  fprapg5   1588848450  IsraelPalestine  t3_gf34wp  t3_gf34wp   \n",
       "2  fprla8t   1588856871  IsraelPalestine  t3_gf34wp  t3_gf34wp   \n",
       "3  fprymsf   1588864482  IsraelPalestine  t3_gf34wp  t3_gf34wp   \n",
       "4  fpta3xd   1588887532  IsraelPalestine  t3_gf34wp  t3_gf34wp   \n",
       "\n",
       "                 author                                               body  \\\n",
       "0          RosintheBow3  I think Israelis are critical of their governm...   \n",
       "1            samtony234  There are many critical Israelis. You have the...   \n",
       "2             JeffB1517  >  Like all other things, criticisms of Israel...   \n",
       "3             zidbutt21  Would you mind translating the Hebrew article ...   \n",
       "4  ShabbatShalomSamurai  I’ve been in Israel the last five months and I...   \n",
       "\n",
       "   score submission_id submission_flair  \n",
       "0     32        gf34wp              NaN  \n",
       "1     17        gf34wp              NaN  \n",
       "2     12        gf34wp              NaN  \n",
       "3      3        gf34wp              NaN  \n",
       "4      3        gf34wp              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments in file: 550,629\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    dfc = pd.read_csv(COMMENTS_CSV)\n",
    "    display(dfc.head(5))\n",
    "    print(f\"Total comments in file: {len(dfc):,}\")\n",
    "except Exception as e:\n",
    "    print(\"Couldn't preview comments CSV:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
